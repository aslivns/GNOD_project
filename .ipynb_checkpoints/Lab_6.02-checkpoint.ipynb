{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "404cf3d1",
   "metadata": {},
   "source": [
    "### FBI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54abff63",
   "metadata": {},
   "source": [
    "Create a Python list with the top ten FBI's Most Wanted names: url = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b1cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "847b1efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e38881d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(url)\n",
    "response.status_code # 200 status code means OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4df1f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8ebfaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup.select('#query-results-0f737222c5054a81a120bce207b0446a > ul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ea8470c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://www.fbi.gov/wanted/topten/yulan-adonay-archaga-carias\">YULAN ADONAY ARCHAGA CARIAS</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/bhadreshkumar-chetanbhai-patel\">BHADRESHKUMAR CHETANBHAI PATEL</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/alejandro-castillo\">ALEJANDRO ROSALES CASTILLO</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/ruja-ignatova\">RUJA IGNATOVA</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/arnoldo-jimenez\">ARNOLDO JIMENEZ</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/omar-alexander-cardenas\">OMAR ALEXANDER CARDENAS</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/alexis-flores\">ALEXIS FLORES</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/jose-rodolfo-villarreal-hernandez\">JOSE RODOLFO VILLARREAL-HERNANDEZ</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/michael-james-pratt\">MICHAEL JAMES PRATT</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/rafael-caro-quintero\">RAFAEL CARO-QUINTERO</a>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"h3 > a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80d3d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "\n",
    "num_iter = len(soup.select(\"h3 > a\"))\n",
    "\n",
    "names_list = soup.select(\"h3 > a\")\n",
    "\n",
    "for i in range(num_iter):\n",
    "    names.append(names_list[i].get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fe345da",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_wanted = pd.DataFrame({'names':names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "910dda91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YULAN ADONAY ARCHAGA CARIAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BHADRESHKUMAR CHETANBHAI PATEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALEJANDRO ROSALES CASTILLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RUJA IGNATOVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARNOLDO JIMENEZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OMAR ALEXANDER CARDENAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ALEXIS FLORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JOSE RODOLFO VILLARREAL-HERNANDEZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MICHAEL JAMES PRATT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RAFAEL CARO-QUINTERO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               names\n",
       "0        YULAN ADONAY ARCHAGA CARIAS\n",
       "1     BHADRESHKUMAR CHETANBHAI PATEL\n",
       "2         ALEJANDRO ROSALES CASTILLO\n",
       "3                      RUJA IGNATOVA\n",
       "4                    ARNOLDO JIMENEZ\n",
       "5            OMAR ALEXANDER CARDENAS\n",
       "6                      ALEXIS FLORES\n",
       "7  JOSE RODOLFO VILLARREAL-HERNANDEZ\n",
       "8                MICHAEL JAMES PRATT\n",
       "9               RAFAEL CARO-QUINTERO"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_wanted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b086c03",
   "metadata": {},
   "source": [
    "### Languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48de092e",
   "metadata": {},
   "source": [
    "Display the top 10 languages by number of native speakers stored in a pandas dataframe: url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dcc49bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = \"https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9b4df9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2 = requests.get(url2)\n",
    "response2.status_code # 200 status code means OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "369d2e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2 = BeautifulSoup(response2.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "729fe963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #languages\n",
    "# soup2.select(\"tbody > tr > td > a.mw-redirect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b26ad16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "language=soup2.find('table',{'class':\"wikitable\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8472c140",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages=pd.read_html(str(language))\n",
    "# convert list to dataframe\n",
    "languages=pd.DataFrame(languages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc56fa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Native speakers (millions)</th>\n",
       "      <th>Language family</th>\n",
       "      <th>Branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mandarin Chinese (incl. Standard Chinese, but ...</td>\n",
       "      <td>920.0</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>475.0</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>373.0</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindi (excl. Urdu)</td>\n",
       "      <td>344.0</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bengali</td>\n",
       "      <td>234.0</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Portuguese</td>\n",
       "      <td>232.0</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Russian</td>\n",
       "      <td>154.0</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Balto-Slavic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>125.0</td>\n",
       "      <td>Japonic</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yue Chinese (incl. Cantonese)</td>\n",
       "      <td>85.2</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>84.6</td>\n",
       "      <td>Austroasiatic</td>\n",
       "      <td>Vietic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Language  \\\n",
       "0  Mandarin Chinese (incl. Standard Chinese, but ...   \n",
       "1                                            Spanish   \n",
       "2                                            English   \n",
       "3                                 Hindi (excl. Urdu)   \n",
       "4                                            Bengali   \n",
       "5                                         Portuguese   \n",
       "6                                            Russian   \n",
       "7                                           Japanese   \n",
       "8                      Yue Chinese (incl. Cantonese)   \n",
       "9                                         Vietnamese   \n",
       "\n",
       "   Native speakers (millions) Language family        Branch  \n",
       "0                       920.0    Sino-Tibetan       Sinitic  \n",
       "1                       475.0   Indo-European       Romance  \n",
       "2                       373.0   Indo-European      Germanic  \n",
       "3                       344.0   Indo-European    Indo-Aryan  \n",
       "4                       234.0   Indo-European    Indo-Aryan  \n",
       "5                       232.0   Indo-European       Romance  \n",
       "6                       154.0   Indo-European  Balto-Slavic  \n",
       "7                       125.0         Japonic      Japanese  \n",
       "8                        85.2    Sino-Tibetan       Sinitic  \n",
       "9                        84.6   Austroasiatic        Vietic  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5c4fc4",
   "metadata": {},
   "source": [
    "## Earthquakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314675ae",
   "metadata": {},
   "source": [
    "Display the 20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe: url = 'https://www.emsc-csem.org/Earthquake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f91d9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url3 = \"https://www.emsc-csem.org/Earthquake/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e84a5ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3 = requests.get(url3)\n",
    "response3.status_code # 200 status code means OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cf91d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup3 = BeautifulSoup(response3.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45802e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup3.select('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12159890",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = soup3.find_all('td',{'class','tabev6'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86718e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'earthquake2023-01-10\\xa0\\xa0\\xa009:17:10.915min ago'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup3.find_all('td',{'class','tabev6'})[0].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dbc3db",
   "metadata": {},
   "source": [
    "Under tabev6 > class= there are 2 times tabev2 and times tabev1. So I found a way findNextSiblings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76b2f386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td class=\"tabev1\">37.29 </td>,\n",
       " <td class=\"tabev2\">N  </td>,\n",
       " <td class=\"tabev1\">15.07 </td>,\n",
       " <td class=\"tabev2\">E  </td>,\n",
       " <td class=\"tabev3\">7</td>,\n",
       " <td class=\"tabev5\" id=\"magtyp0\">ML</td>,\n",
       " <td class=\"tabev2\">2.6</td>,\n",
       " <td class=\"tb_region\" id=\"reg0\"> SICILY, ITALY</td>,\n",
       " <td class=\"comment updatetimeno\" id=\"upd0\" style=\"text-align:right;\">2023-01-10 09:29</td>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroth_ratio_sibs = ratio[0].findNextSiblings()\n",
    "zeroth_ratio_sibs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "651a4c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude_list = list(zeroth_ratio_sibs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07b909d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude_direction_list = list(zeroth_ratio_sibs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40f1c77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude_list = list(zeroth_ratio_sibs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37579bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude_direction_list = list(zeroth_ratio_sibs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d58e6d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude_list = list(zeroth_ratio_sibs[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c809259",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_list = list(zeroth_ratio_sibs[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebcfc5f",
   "metadata": {},
   "source": [
    "I will put the results' first values in a list and remove \\xa0 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2e087a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time = []\n",
    "latitude = []\n",
    "latitude_direction = []\n",
    "longitude = []\n",
    "longitude_direction = []\n",
    "magnitude = []\n",
    "region = []\n",
    "\n",
    "for i in range(0,20):\n",
    "    zeroth_ratio_sibs = ratio[i].findNextSiblings()\n",
    "    date_time.append(soup3.find_all('td',{'class','tabev6'})[i].get_text())\n",
    "    latitude.append(list(zeroth_ratio_sibs[0])[0].replace('\\xa0', ''))\n",
    "    latitude_direction.append(list(zeroth_ratio_sibs[1])[0].replace('\\xa0', ''))\n",
    "    longitude.append(list(zeroth_ratio_sibs[2])[0].replace('\\xa0', ''))\n",
    "    longitude_direction.append(list(zeroth_ratio_sibs[3])[0].replace('\\xa0', ''))\n",
    "    magnitude.append(list(zeroth_ratio_sibs[6])[0].replace('\\xa0', ''))  \n",
    "    region.append(list(zeroth_ratio_sibs[7])[0].replace('\\xa0', ''))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0fdd56",
   "metadata": {},
   "source": [
    "Combining latitude&longitude and their directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a386605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "lat = reduce(lambda res, l: res + [l[0] + \" \" + l[1]], zip(latitude, latitude_direction), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69a57e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "long = reduce(lambda res, l: res + [l[0] + \" \" + l[1]], zip(longitude, longitude_direction), [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3febf1",
   "metadata": {},
   "source": [
    "Clean date and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6930352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd5ee29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern_date = '(\\d{4}-\\d{2}-\\d{2})'\n",
    "pattern_time = '(\\d{2}:\\d{2}:\\d{2})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14f2bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = []\n",
    "for i in range(0,20):\n",
    "    date.append(re.findall(pattern_date, date_time[i])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1aefa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = []\n",
    "for i in range(0,20):\n",
    "    time.append(re.findall(pattern_time, date_time[i])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84104370",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_earthquakes = pd.DataFrame({\"date\":date, \"time\":time, \"latitude\":lat, \"longitude\":long,\"region\":region, \"magnitude\":magnitude})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc65202c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>region</th>\n",
       "      <th>magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>09:17:10</td>\n",
       "      <td>37.29 N</td>\n",
       "      <td>15.07 E</td>\n",
       "      <td>SICILY, ITALY</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>09:05:46</td>\n",
       "      <td>55.34 N</td>\n",
       "      <td>149.27 W</td>\n",
       "      <td>GULF OF ALASKA</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>09:04:16</td>\n",
       "      <td>9.32 S</td>\n",
       "      <td>117.84 E</td>\n",
       "      <td>SUMBAWA REGION, INDONESIA</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>08:56:30</td>\n",
       "      <td>39.10 N</td>\n",
       "      <td>142.10 E</td>\n",
       "      <td>NEAR EAST COAST OF HONSHU, JAPAN</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>08:43:32</td>\n",
       "      <td>39.38 N</td>\n",
       "      <td>26.25 E</td>\n",
       "      <td>NEAR THE COAST OF WESTERN TURKEY</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>08:38:21</td>\n",
       "      <td>34.90 N</td>\n",
       "      <td>25.45 E</td>\n",
       "      <td>CRETE, GREECE</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>08:32:31</td>\n",
       "      <td>39.37 N</td>\n",
       "      <td>26.23 E</td>\n",
       "      <td>NEAR THE COAST OF WESTERN TURKEY</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>08:27:46</td>\n",
       "      <td>12.25 N</td>\n",
       "      <td>88.14 W</td>\n",
       "      <td>NEAR COAST OF NICARAGUA</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>08:26:44</td>\n",
       "      <td>39.37 N</td>\n",
       "      <td>26.24 E</td>\n",
       "      <td>NEAR THE COAST OF WESTERN TURKEY</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>08:23:47</td>\n",
       "      <td>38.56 N</td>\n",
       "      <td>23.68 E</td>\n",
       "      <td>GREECE</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>08:21:24</td>\n",
       "      <td>10.65 S</td>\n",
       "      <td>166.06 E</td>\n",
       "      <td>SANTA CRUZ ISLANDS</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>08:17:56</td>\n",
       "      <td>35.55 N</td>\n",
       "      <td>25.80 E</td>\n",
       "      <td>CRETE, GREECE</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>08:12:28</td>\n",
       "      <td>39.37 N</td>\n",
       "      <td>26.27 E</td>\n",
       "      <td>NEAR THE COAST OF WESTERN TURKEY</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>08:09:36</td>\n",
       "      <td>13.00 N</td>\n",
       "      <td>87.83 W</td>\n",
       "      <td>NICARAGUA</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>08:04:30</td>\n",
       "      <td>38.60 N</td>\n",
       "      <td>141.90 E</td>\n",
       "      <td>NEAR EAST COAST OF HONSHU, JAPAN</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>07:58:52</td>\n",
       "      <td>39.33 N</td>\n",
       "      <td>26.28 E</td>\n",
       "      <td>NEAR THE COAST OF WESTERN TURKEY</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>07:44:35</td>\n",
       "      <td>39.38 N</td>\n",
       "      <td>26.27 E</td>\n",
       "      <td>NEAR THE COAST OF WESTERN TURKEY</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>07:43:04</td>\n",
       "      <td>39.39 N</td>\n",
       "      <td>26.23 E</td>\n",
       "      <td>NEAR THE COAST OF WESTERN TURKEY</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>07:42:58</td>\n",
       "      <td>38.17 N</td>\n",
       "      <td>74.18 E</td>\n",
       "      <td>TAJIKISTAN</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>07:41:52</td>\n",
       "      <td>7.18 S</td>\n",
       "      <td>129.94 E</td>\n",
       "      <td>KEPULAUAN BABAR, INDONESIA</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date      time latitude longitude                            region  \\\n",
       "0   2023-01-10  09:17:10  37.29 N   15.07 E                     SICILY, ITALY   \n",
       "1   2023-01-10  09:05:46  55.34 N  149.27 W                    GULF OF ALASKA   \n",
       "2   2023-01-10  09:04:16   9.32 S  117.84 E         SUMBAWA REGION, INDONESIA   \n",
       "3   2023-01-10  08:56:30  39.10 N  142.10 E  NEAR EAST COAST OF HONSHU, JAPAN   \n",
       "4   2023-01-10  08:43:32  39.38 N   26.25 E  NEAR THE COAST OF WESTERN TURKEY   \n",
       "5   2023-01-10  08:38:21  34.90 N   25.45 E                     CRETE, GREECE   \n",
       "6   2023-01-10  08:32:31  39.37 N   26.23 E  NEAR THE COAST OF WESTERN TURKEY   \n",
       "7   2023-01-10  08:27:46  12.25 N   88.14 W           NEAR COAST OF NICARAGUA   \n",
       "8   2023-01-10  08:26:44  39.37 N   26.24 E  NEAR THE COAST OF WESTERN TURKEY   \n",
       "9   2023-01-10  08:23:47  38.56 N   23.68 E                            GREECE   \n",
       "10  2023-01-10  08:21:24  10.65 S  166.06 E                SANTA CRUZ ISLANDS   \n",
       "11  2023-01-10  08:17:56  35.55 N   25.80 E                     CRETE, GREECE   \n",
       "12  2023-01-10  08:12:28  39.37 N   26.27 E  NEAR THE COAST OF WESTERN TURKEY   \n",
       "13  2023-01-10  08:09:36  13.00 N   87.83 W                         NICARAGUA   \n",
       "14  2023-01-10  08:04:30  38.60 N  141.90 E  NEAR EAST COAST OF HONSHU, JAPAN   \n",
       "15  2023-01-10  07:58:52  39.33 N   26.28 E  NEAR THE COAST OF WESTERN TURKEY   \n",
       "16  2023-01-10  07:44:35  39.38 N   26.27 E  NEAR THE COAST OF WESTERN TURKEY   \n",
       "17  2023-01-10  07:43:04  39.39 N   26.23 E  NEAR THE COAST OF WESTERN TURKEY   \n",
       "18  2023-01-10  07:42:58  38.17 N   74.18 E                        TAJIKISTAN   \n",
       "19  2023-01-10  07:41:52   7.18 S  129.94 E        KEPULAUAN BABAR, INDONESIA   \n",
       "\n",
       "   magnitude  \n",
       "0        2.6  \n",
       "1        4.0  \n",
       "2        2.7  \n",
       "3        3.5  \n",
       "4        3.0  \n",
       "5        3.7  \n",
       "6        2.8  \n",
       "7        4.7  \n",
       "8        2.5  \n",
       "9        3.0  \n",
       "10       5.0  \n",
       "11       2.9  \n",
       "12       2.8  \n",
       "13       2.5  \n",
       "14       3.9  \n",
       "15       2.8  \n",
       "16       2.5  \n",
       "17       2.7  \n",
       "18       4.4  \n",
       "19       4.1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_earthquakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d5efe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80e8483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d66dc58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
